{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and config\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys",
    "sys.path.append('..')",
    "\n",
    "from sod_model import get_sod_model\n",
    "\n",
    "# Path to checkpoint (change if needed)\n",
    "CHECKPOINT_DIR = '/home/aliho/sod_tf_project/checkpoints_exp7_DEEP\n",
    "BEST_WEIGHTS = os.path.join(CHECKPOINT_DIR, 'best_model.weights.h5')\n",
    "\n",
    "# Model config (match training)\n",
    "TARGET_SIZE = 224\n",
    "BASE_FILTERS = 32\n",
    "NUM_BLOCKS = 5\n",
    "USE_BATCHNORM = True\n",
    "USE_DROPOUT = True\n",
    "DROPOUT_RATE = 0.5\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: load model and weights (returns a compiled model-like object we can call)\n",
    "def load_model(checkpoint_path=BEST_WEIGHTS, target_size=TARGET_SIZE, base_filters=BASE_FILTERS, num_blocks=NUM_BLOCKS, use_batchnorm=USE_BATCHNORM, use_dropout=USE_DROPOUT, dropout_rate=DROPOUT_RATE):\n",
    "    model = get_sod_model(input_shape=(target_size, target_size, 3), base_filters=base_filters, use_batchnorm=use_batchnorm, use_dropout=use_dropout, dropout_rate=dropout_rate, num_blocks=num_blocks)\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            model.load_weights(checkpoint_path)\n",
    "            print(f'Loaded weights from {checkpoint_path}')\n",
    "        except Exception as e:\n",
    "            print('Could not load weights:', e)\n",
    "    else:\n",
    "        print(f'Weights not found at {checkpoint_path} — model is uninitialized')\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess an image (bytes or path)\n",
    "def preprocess_image_from_bytes(img_bytes, target_size=TARGET_SIZE):\n",
    "    img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "    img = img.resize((target_size, target_size), Image.BILINEAR)\n",
    "    arr = np.array(img).astype('float32') / 255.0\n",
    "    return arr\n",
    "\n",
    "def preprocess_image_from_path(path, target_size=TARGET_SIZE):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img = img.resize((target_size, target_size), Image.BILINEAR)\n",
    "    arr = np.array(img).astype('float32') / 255.0\n",
    "    return arr\n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    # mask expected 0..1 float, shape (H,W)\n",
    "    m = np.clip(mask, 0.0, 1.0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference helper that measures time and returns mask + time (seconds)\n",
    "def infer_image(model, img_arr):\n",
    "    # img_arr: HxWx3 float32 in [0,1]\n",
    "    inp = np.expand_dims(img_arr, axis=0).astype('float32')\n",
    "    t0 = time.time()\n",
    "    pred = model(inp, training=False).numpy()\n",
    "    t1 = time.time()\n",
    "    mask = pred[0, ..., 0] if pred.ndim == 4 else pred[0]\n",
    "    return postprocess_mask(mask), (t1 - t0)\n",
    "\n",
    "def show_results(img_arr, mask, inference_time):\n",
    "    # img_arr: HxWx3 in [0,1], mask: HxW in [0,1]\n",
    "    h, w = mask.shape\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(img_arr)\n",
    "    axes[0].set_title('Input')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(mask, cmap='gray')\n",
    "    axes[1].set_title('Predicted Mask')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # overlay: red mask on image\n",
    "    overlay = (img_arr * 255).astype('uint8').copy()\n",
    "    alpha = np.clip(mask[..., None], 0, 1) * 0.6\n",
    "    red = np.zeros_like(overlay)\n",
    "    red[..., 0] = (mask * 255).astype('uint8')\n",
    "    overlay = (overlay * (1 - alpha) + red * alpha).astype('uint8')\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(f'Overlay — {inference_time*1000:.1f} ms')\n",
    "    axes[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload widget if available, otherwise fallback to path-based inference\n",
    "IMAGE_PATH = '/home/aliho/sod_tf_project/data/DUTS-TE/DUTS-TE/DUTS-TE-Image/ILSVRC2012_test_00000259.jpg'  # this is a linux path to an image on my local machine, specifically data/duts-te/duts-te-image. If you want to use the upload widget, set this to None and run the cell below.\n",
    "\n",
    "# Try ipywidgets upload widget\n",
    "try:\n",
    "    from ipywidgets import FileUpload, Button, HBox, VBox, Output\n",
    "    uploader = FileUpload(accept='image/*', multiple=False)\n",
    "    run_btn = Button(description='Run inference')\n",
    "    out = Output()\n",
    "\n",
    "    display(VBox([uploader, run_btn, out]))\n",
    "\n",
    "    def on_run(b):\n",
    "        out.clear_output()\n",
    "        if uploader.value:\n",
    "            # `uploader.value` is a dict-like in many jupyter versions\n",
    "            item = list(uploader.value.values())[0] if isinstance(uploader.value, dict) else uploader.value[0]\n",
    "            content = item['content'] if isinstance(item, dict) and 'content' in item else item\n",
    "            img_arr = preprocess_image_from_bytes(content, TARGET_SIZE)\n",
    "            mask, dt = infer_image(model, img_arr)\n",
    "            with out:\n",
    "                show_results(img_arr, mask, dt)\n",
    "        elif IMAGE_PATH:\n",
    "            img_arr = preprocess_image_from_path(IMAGE_PATH, TARGET_SIZE)\n",
    "            mask, dt = infer_image(model, img_arr)\n",
    "            with out:\n",
    "                show_results(img_arr, mask, dt)\n",
    "        else:\n",
    "            with out:\n",
    "                print('No image uploaded or IMAGE_PATH set.')\n",
    "\n",
    "    run_btn.on_click(on_run)\n",
    "except Exception as e:\n",
    "    print('Upload widget not available or failed to instantiate:', e)\n",
    "    print('You can instead set IMAGE_PATH to a local file and run the cell below to perform inference.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback: run inference on a path you set in IMAGE_PATH and display results\n",
    "if IMAGE_PATH:\n",
    "    arr = preprocess_image_from_path(IMAGE_PATH, TARGET_SIZE)\n",
    "    mask, dt = infer_image(model, arr)\n",
    "    show_results(arr, mask, dt)\n",
    "else:\n",
    "    print('No IMAGE_PATH set. Use the upload widget above, or set IMAGE_PATH and re-run this cell.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
